Grammarly uses innovation NLP technology to not only correct grammar and spelling but also enhance the overall quality of written content by providing suggestions for clarity, tone and style. For example, while composing an email or a document it could be hard to articulate thoughts clearly and important ideas might be buried in text or the paragraph structure could be confusing and readers might not grasp what the text is all about. Grammarly helps people communicate more effectively by using innovative technologies like NLP (Natural Language Processing) and ML (Machine Learning) abd providing efficient suggestions for improvements of email or any texts in documents.

They achieved this by breaking the technical problem into two pieces:
1. Extracting the main points from the text
2. Detecting where the reader is likely to focus their attention in the text

The first point is a familiar problem in ML and NLP but grammarly uses a different approach for this problem. Grammarly technique involves separating action items from main points. For example, an action item could be "Please complete this task by end of day" and a main point could be "Project has been delayed by 3 weeks". Creating separate buckets for action and main items enables to improve accuracy of the model and also enable future ML-powered features around action items.

Secondly, an importance score is assigned around the main points in a message. When working with annotated data , the scores could be averaged or normalised by different people to achieve a general consensus.

This was the framework which grammarly adopted to collect truth data with annotators. Annotators were asked to identify main points and action item sentences in a set of representative email texts and also judge the importance of each main point.

The next step was developing the model. 
1. Extractive summarization was done to extracting main points from text. This is a well-studied problem in NLP field. PageRank algorithm which finds important websites based on how well-connected they are to other pages on the web was used. LexRank and TextRank use the same approach to try and find important sentences based on how well connected they are to other sentences in the text. While PageRank measures the number of links between pages, LexRank and TextRank look at the number of words that a sentence has in common with other sentences in the text.
Initially a large dataset was not available to Grammarly to use a deeper learning algorithm like BERTSUM which is highly effective but requires large training data.BERTSUM is the more modern approach to text summarisation which involves running the text through a massive language model to get a latent representation for each sentence, and use labeled training data  to teach the model which sentences are the main points and which aren't. The model then finds the sentences that have the highest probability of being the main points. A deep learning approach like this is quite effective but needs lots of training data which Grammarly initially did not have hence they resorted to using LexRank and TextRank based on PageRank.

2. Robust set of language-based features were developed by in house analytical linguists. In smaller text the main point is found at the beginning or end and in larger documents the title or subject indicates this. Approaches like these were used to identify the features.

3. Optimizing model The model was initially slow on longer texts, so various optimization strategies to reduce the scope of the problem and bring down the modelâ€™s inference times were performed. If there are 10 sentences the main points could be any of the 10 sentences which is 2^10 possibilities which is fine. But if 10 more sentences are added then the complexity increases. So instead of working with all sentences an approach based on sampling is used. Random sentences were selected and scored against the features. The next time sampling happens, the bias was towards the top scoring sentences and finally a best subset was arrived at. Additional approaches were also used like dropping  sentences like salutations or signatures and only sentences towards main points were considered. These kind of optimization strategies helped reduce the latency and improve response times.

Overall, Grammarly achieved a model that performed with 80% precision, and with the development of robust annotated datasets,  were recently able to move to a deep learning approach that preserved the same level of precision while improving recall from 40% up to 62%. 
